{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25618b64-9024-49e8-8a18-4f32399e9ca7",
   "metadata": {},
   "source": [
    "#### In HW3 you did an exercise on performing a classification on the **HeartData.csv** data file. We recently learned how to apply the LOOCV and K-Fold CV to regression problems. In this homework we would like to apply the LOOCV and K-Fold CV to the logistic regression, LDA and QDA models used in HW3. Using 10-fold CV and LOOCV fit the models and report the classification accuracy for the 3 models (logistic regression, LDA and QDA).For this question use num as the response variable and all the other variables as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3447c327-9d47-4511-90f0-f9dbf3dfdc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from ISLP.models import sklearn_sm\n",
    "from ISLP.models import (ModelSpec as MS,summarize)\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.model_selection import cross_validate, LeaveOneOut, KFold, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94d45e-6d44-42ba-9d93-0b6807d845a2",
   "metadata": {},
   "source": [
    "# = = = = = Running LOOCV = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea34c10-a2e9-4328-b16f-369e5fe4350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('HeartData-1.csv')\n",
    "X_LR = MS(Data.columns.drop(['num'])).fit_transform(Data) # with intercept\n",
    "X = Data.drop(['num'], axis = 1) # without intercept\n",
    "y = Data['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ebeb43-3f0b-4845-8f8f-e681d9a637e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_leave_one_out(X, y, i):\n",
    "    # training data size 296\n",
    "    X_train = X.drop(i)\n",
    "    y_train = y.drop(i)\n",
    "\n",
    "    # test data size 1\n",
    "    X_test = X.iloc[i:i+1]\n",
    "    y_test = y.iloc[i]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7637e61-efc4-4aac-b1b0-9da22ca13965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ ~ ~ ~ ~ 1. Logistic Regression Model ~ ~ ~ ~ ~\n",
      "0.12403120021860257\n"
     ]
    }
   ],
   "source": [
    "print('~ ~ ~ ~ ~ 1. Logistic Regression Model ~ ~ ~ ~ ~')\n",
    "MSE_LR = np.zeros(len(Data))\n",
    "for i in range(len(Data)):\n",
    "    X_train, y_train, X_test, y_test = split_data_leave_one_out(X_LR, y, i)\n",
    "    # fit model\n",
    "    lrm = sm.GLM(y_train, X_train, family=sm.families.Binomial()).fit()\n",
    "    # predict the left one sample\n",
    "    pred = lrm.predict(exog=X_test)\n",
    "    # calculate MSE\n",
    "    MSE_LR[i] = mean_squared_error([y_test], [pred])\n",
    "print(np.mean(MSE_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a7efc3-e831-4094-b4a6-faf050cfa41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ ~ ~ ~ ~ 2. LDA Model ~ ~ ~ ~ ~\n",
      "0.16498316498316498\n"
     ]
    }
   ],
   "source": [
    "print('~ ~ ~ ~ ~ 2. LDA Model ~ ~ ~ ~ ~')\n",
    "lda = LDA(store_covariance=True)\n",
    "MSE_LDA = np.zeros(len(Data))\n",
    "for i in range(len(Data)):\n",
    "    X_train, y_train, X_test, y_test = split_data_leave_one_out(X, y, i)\n",
    "    # fit model\n",
    "    lda.fit(X_train, y_train)\n",
    "    # predict the left one sample\n",
    "    pred = lda.predict(X_test)\n",
    "    # calculate MSE\n",
    "    MSE_LDA[i] = mean_squared_error([y_test], [pred])\n",
    "print(np.mean(MSE_LDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fec09a7-5fed-4a49-9c8b-1375352158ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ ~ ~ ~ ~ 3. QDA Model ~ ~ ~ ~ ~\n",
      "0.1750841750841751\n"
     ]
    }
   ],
   "source": [
    "print('~ ~ ~ ~ ~ 3. QDA Model ~ ~ ~ ~ ~')\n",
    "qda = QDA(store_covariance=True)\n",
    "MSE_QDA = np.zeros(len(Data))\n",
    "\n",
    "for i in range(len(Data)):\n",
    "    X_train, y_train, X_test, y_test = split_data_leave_one_out(X, y, i)\n",
    "    # fit model\n",
    "    qda.fit(X_train, y_train)\n",
    "    # predict the left one sample value\n",
    "    pred = qda.predict(X_test)\n",
    "    # calculate MSE\n",
    "    MSE_QDA[i] = mean_squared_error([y_test], [pred])\n",
    "print(np.mean(MSE_QDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d68a08-4ee7-48d5-a466-0e3c2de6d95a",
   "metadata": {},
   "source": [
    "# = = = = = Running 10-Fold = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f63d3a-62cf-48fa-b2aa-a777d21dad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_10_Fold_chunks(X, y, train_index, test_index):\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630ad866-ce98-4266-a271-c879da6eef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV error: 0.0009922927494102863\n",
      "LDA CV error: 0.0\n",
      "QDA CV error: 0.0\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "MSE_LR = np.zeros(len(Data))\n",
    "MSE_LDA = np.zeros(len(Data))\n",
    "MSE_QDA = np.zeros(len(Data))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(Data)):\n",
    "    # print(f\"Fold {i}:\")\n",
    "    # print(f\"  Train: index={train_index}\")\n",
    "    # print(f\"  Test:  index={test_index}\")\n",
    "    X_train_LR, y_train, X_test_LR, y_test = split_data_leave_one_out(X_LR, y, i)\n",
    "    X_train = X_train_LR.drop(['intercept'], axis = 1)\n",
    "    X_test = X_test_LR.drop(['intercept'], axis = 1)\n",
    "    \n",
    "    # fit model\n",
    "    lrm = sm.GLM(y_train, X_train_LR, family=sm.families.Binomial()).fit()\n",
    "    lda.fit(X_train, y_train)\n",
    "    qda.fit(X_train, y_train)\n",
    "    \n",
    "    # predict the values\n",
    "    pred_LR = lrm.predict(exog=X_test_LR)\n",
    "    pred_LDA = lda.predict(X_test)\n",
    "    pred_QDA = qda.predict(X_test)\n",
    "    \n",
    "    # calculate MSE\n",
    "    MSE_LR[i] = mean_squared_error([y_test], [pred_LR])\n",
    "    MSE_LDA[i] = mean_squared_error([y_test], [pred_LDA])\n",
    "    MSE_QDA[i] = mean_squared_error([y_test], [pred_QDA])\n",
    "    \n",
    "print(\"Logistic Regression CV error:\", np.mean(MSE_LR))\n",
    "print(\"LDA CV error:\", np.mean(MSE_LDA))\n",
    "print(\"QDA CV error:\", np.mean(MSE_QDA))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
