{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25618b64-9024-49e8-8a18-4f32399e9ca7",
   "metadata": {},
   "source": [
    "#### In HW3 you did an exercise on performing a classification on the **HeartData.csv** data file. We recently learned how to apply the LOOCV and K-Fold CV to regression problems. In this homework we would like to apply the LOOCV and K-Fold CV to the logistic regression, LDA and QDA models used in HW3. Using 10-fold CV and LOOCV fit the models and report the classification accuracy for the 3 models (logistic regression, LDA and QDA).For this question use num as the response variable and all the other variables as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3447c327-9d47-4511-90f0-f9dbf3dfdc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from ISLP.models import sklearn_sm\n",
    "from ISLP.models import (ModelSpec as MS,summarize)\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.model_selection import cross_validate, LeaveOneOut, KFold, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from ISLP import confusion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea34c10-a2e9-4328-b16f-369e5fe4350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('HeartData-1.csv')\n",
    "y = Data['num']\n",
    "X = Data.drop(['num'], axis = 1) # without intercept\n",
    "X_LR = MS(X).fit_transform(Data) # with intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d68a08-4ee7-48d5-a466-0e3c2de6d95a",
   "metadata": {},
   "source": [
    "# = = = = = Running 10-Fold = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f63d3a-62cf-48fa-b2aa-a777d21dad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_10_Fold_chunks(X, y, train_index, test_index):\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107f6b26-d796-41dc-9b46-b4b00344e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(probs, y_test):\n",
    "    labels = (probs > 0.5)\n",
    "    return np.mean(labels == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0af10a-2f69-440c-9b7e-e7fa645bf44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LDA/QDA model\n",
    "lda = LDA(store_covariance=True)\n",
    "qda = QDA(store_covariance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a7c535d-1b3b-43bf-be15-03c8fca2ba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ ~ ~ ~ ~ Accuracy ~ ~ ~ ~ ~\n",
      "Logistic Regression: 0.8282758620689655\n",
      "LDA: 0.8383908045977012\n",
      "QDA: 0.8185057471264369\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "PROB_LR = np.zeros(K)\n",
    "PROB_LDA = np.zeros(K)\n",
    "PROB_QDA = np.zeros(K)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(Data)):\n",
    "    X_train_LR, y_train, X_test_LR, y_test = split_into_10_Fold_chunks(X_LR, y, train_index, test_index)\n",
    "    X_train = X_train_LR.drop(['intercept'], axis = 1)\n",
    "    X_test = X_test_LR.drop(['intercept'], axis = 1)\n",
    "    \n",
    "    # fit model\n",
    "    lrm = sm.GLM(y_train, X_train_LR, family=sm.families.Binomial()).fit()\n",
    "    lda.fit(X_train, y_train)\n",
    "    qda.fit(X_train, y_train)\n",
    "    \n",
    "    # predict the values\n",
    "    probs_LR = lrm.predict(exog=X_test_LR)\n",
    "    probs_LDA = lda.predict(X_test)\n",
    "    probs_QDA = qda.predict(X_test)\n",
    "    \n",
    "    # save accuracy\n",
    "    labels = (probs_LR > 0.5)\n",
    "    PROB_LR[i] = np.mean(labels == y_test)\n",
    "    PROB_LDA[i] = np.mean(probs_LDA == y_test)\n",
    "    PROB_QDA[i] = np.mean(probs_QDA == y_test)\n",
    "\n",
    "print('~ ~ ~ ~ ~ Accuracy ~ ~ ~ ~ ~')\n",
    "print(\"Logistic Regression:\", np.mean(PROB_LR))\n",
    "print(\"LDA:\", np.mean(PROB_LDA))\n",
    "print(\"QDA:\", np.mean(PROB_QDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94d45e-6d44-42ba-9d93-0b6807d845a2",
   "metadata": {},
   "source": [
    "# = = = = = Running LOOCV = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ebeb43-3f0b-4845-8f8f-e681d9a637e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_leave_one_out(X, y, i):\n",
    "    # training data size 296\n",
    "    X_train = X.drop(i)\n",
    "    y_train = y.drop(i)\n",
    "    # test data size 1\n",
    "    X_test = X.iloc[i:i+1]\n",
    "    y_test = y.iloc[i]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4440a284-bbd3-4fa3-8231-b3daf9615926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ ~ ~ ~ ~ Accuracy ~ ~ ~ ~ ~\n",
      "Logistic Regression: 0.8249158249158249\n",
      "LDA: 0.835016835016835\n",
      "QDA: 0.8249158249158249\n"
     ]
    }
   ],
   "source": [
    "PROB_LR = np.zeros(len(Data))\n",
    "PROB_LDA = np.zeros(len(Data))\n",
    "PROB_QDA = np.zeros(len(Data))\n",
    "\n",
    "for i in range(len(Data)):\n",
    "    X_train_LR, y_train, X_test_LR, y_test = split_data_leave_one_out(X_LR, y, i)\n",
    "    X_train = X_train_LR.drop(['intercept'], axis = 1)\n",
    "    X_test = X_test_LR.drop(['intercept'], axis = 1)\n",
    "    \n",
    "    # fit model\n",
    "    lrm = sm.GLM(y_train, X_train_LR, family=sm.families.Binomial()).fit()\n",
    "    lda.fit(X_train, y_train)\n",
    "    qda.fit(X_train, y_train)\n",
    "    \n",
    "    # predict the values\n",
    "    probs_LR = lrm.predict(exog=X_test_LR)\n",
    "    probs_LDA = lda.predict(X_test)\n",
    "    probs_QDA = qda.predict(X_test)\n",
    "    \n",
    "    # save accuracy\n",
    "    labels_loocv = (probs_LR > 0.5)\n",
    "    PROB_LR[i] = np.mean(labels_loocv == y_test)\n",
    "    PROB_LDA[i] = np.mean(probs_LDA == y_test)\n",
    "    PROB_QDA[i] = np.mean(probs_QDA == y_test)\n",
    "\n",
    "print('~ ~ ~ ~ ~ Accuracy ~ ~ ~ ~ ~')\n",
    "print(\"Logistic Regression:\", np.mean(PROB_LR))\n",
    "print(\"LDA:\", np.mean(PROB_LDA))\n",
    "print(\"QDA:\", np.mean(PROB_QDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12dc45-5ab1-49a5-af8c-b6dd337ec645",
   "metadata": {},
   "source": [
    "#### For 10-Fold CV, LDA has the best accuracy, 83.84%, among the three models.\n",
    "#### For LOOCV, LDA still has the best accuracy, 83.5%, among the three models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
