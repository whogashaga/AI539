{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0dea78b",
   "metadata": {},
   "source": [
    "Importing the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8513fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0436a8e",
   "metadata": {},
   "source": [
    "We also need to import some custom functions and data files related to our textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b673d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e2979",
   "metadata": {},
   "source": [
    "# Classification on Stock Data\n",
    "This data set consists of percentage returns for the S&P 500 stock index over 1,250 days, from the beginning of 2001 until the end of 2005. For each date, we have recorded the percentage returns for each of the five previous trading days, Lag1 through Lag5. We have also recorded Volume (the number of shares traded on the previous day, in billions), Today (the percentage return on the date in question) and Direction (whether the market was Up or Down on this date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a961d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year   Lag1   Lag2   Lag3   Lag4   Lag5   Volume  Today Direction\n",
      "0     2001  0.381 -0.192 -2.624 -1.055  5.010  1.19130  0.959        Up\n",
      "1     2001  0.959  0.381 -0.192 -2.624 -1.055  1.29650  1.032        Up\n",
      "2     2001  1.032  0.959  0.381 -0.192 -2.624  1.41120 -0.623      Down\n",
      "3     2001 -0.623  1.032  0.959  0.381 -0.192  1.27600  0.614        Up\n",
      "4     2001  0.614 -0.623  1.032  0.959  0.381  1.20570  0.213        Up\n",
      "...    ...    ...    ...    ...    ...    ...      ...    ...       ...\n",
      "1245  2005  0.422  0.252 -0.024 -0.584 -0.285  1.88850  0.043        Up\n",
      "1246  2005  0.043  0.422  0.252 -0.024 -0.584  1.28581 -0.955      Down\n",
      "1247  2005 -0.955  0.043  0.422  0.252 -0.024  1.54047  0.130        Up\n",
      "1248  2005  0.130 -0.955  0.043  0.422  0.252  1.42236 -0.298      Down\n",
      "1249  2005 -0.298  0.130 -0.955  0.043  0.422  1.38254 -0.489      Down\n",
      "\n",
      "[1250 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the data\n",
    "Smarket = load_data('Smarket')\n",
    "print(Smarket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee2c7db",
   "metadata": {},
   "source": [
    "# Running Logisitc Regression on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ebcb957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = (Smarket.Year < 2005)\n",
    "Smarket_train = Smarket.loc[train]\n",
    "Smarket_test = Smarket.loc[~train]\n",
    "Smarket_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2cc2e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume'], dtype='object')\n",
      "===========================================================================\n",
      "0        True\n",
      "1        True\n",
      "2       False\n",
      "3        True\n",
      "4        True\n",
      "        ...  \n",
      "1245     True\n",
      "1246    False\n",
      "1247     True\n",
      "1248    False\n",
      "1249    False\n",
      "Name: Direction, Length: 1250, dtype: bool\n",
      "===========================================================================\n",
      "998     0.528220\n",
      "999     0.515669\n",
      "1000    0.522652\n",
      "1001    0.513854\n",
      "1002    0.498334\n",
      "          ...   \n",
      "1245    0.483637\n",
      "1246    0.506048\n",
      "1247    0.516658\n",
      "1248    0.516124\n",
      "1249    0.508072\n",
      "Length: 252, dtype: float64\n",
      "===========================================================================\n",
      "Truth      Down  Up\n",
      "Predicted          \n",
      "Down         77  97\n",
      "Up           34  44\n",
      "===========================================================================\n",
      "0.4801587301587302 0.5198412698412699\n"
     ]
    }
   ],
   "source": [
    "allvars = Smarket.columns.drop(['Today', 'Direction', 'Year'])\n",
    "print(allvars)\n",
    "print('===========================================================================')\n",
    "design = MS(allvars)\n",
    "\n",
    "X = design.fit_transform(Smarket)\n",
    "y = Smarket.Direction == 'Up'\n",
    "print(y)\n",
    "print('===========================================================================')\n",
    "\n",
    "X_train, X_test = X.loc[train], X.loc[~train]\n",
    "y_train, y_test = y.loc[train], y.loc[~train]\n",
    "\n",
    "glm_train = sm.GLM(y_train,\n",
    "                   X_train,\n",
    "                   family=sm.families.Binomial()) # Binomial family is useful for binary outcomes.\n",
    "results = glm_train.fit()\n",
    "\n",
    "probs = results.predict(exog=X_test) # to apply the model to the test data\n",
    "print(probs)\n",
    "\n",
    "labels = np.array(['Down']*Smarket_test.shape[0])\n",
    "labels[probs>0.5] = \"Up\"\n",
    "print('===========================================================================')\n",
    "print(confusion_table(labels, Smarket.Direction[~train]))\n",
    "# extracting the true labels from the data\n",
    "L_test = Smarket.Direction.loc[~train]\n",
    "print('===========================================================================')\n",
    "print(np.mean(labels == L_test), np.mean(labels != L_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bad03",
   "metadata": {},
   "source": [
    "The results are rather disappointing: the test error rate is 52%, which is worse than random guessing! Let's reduce the number of features and see if we can further improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01b48b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year   Lag1   Lag2   Lag3   Lag4   Lag5   Volume  Today Direction\n",
      "0     2001  0.381 -0.192 -2.624 -1.055  5.010  1.19130  0.959        Up\n",
      "1     2001  0.959  0.381 -0.192 -2.624 -1.055  1.29650  1.032        Up\n",
      "2     2001  1.032  0.959  0.381 -0.192 -2.624  1.41120 -0.623      Down\n",
      "3     2001 -0.623  1.032  0.959  0.381 -0.192  1.27600  0.614        Up\n",
      "4     2001  0.614 -0.623  1.032  0.959  0.381  1.20570  0.213        Up\n",
      "...    ...    ...    ...    ...    ...    ...      ...    ...       ...\n",
      "1245  2005  0.422  0.252 -0.024 -0.584 -0.285  1.88850  0.043        Up\n",
      "1246  2005  0.043  0.422  0.252 -0.024 -0.584  1.28581 -0.955      Down\n",
      "1247  2005 -0.955  0.043  0.422  0.252 -0.024  1.54047  0.130        Up\n",
      "1248  2005  0.130 -0.955  0.043  0.422  0.252  1.42236 -0.298      Down\n",
      "1249  2005 -0.298  0.130 -0.955  0.043  0.422  1.38254 -0.489      Down\n",
      "\n",
      "[1250 rows x 9 columns]\n",
      "998     0.509827\n",
      "999     0.520824\n",
      "1000    0.533263\n",
      "1001    0.526057\n",
      "1002    0.507210\n",
      "          ...   \n",
      "1245    0.499384\n",
      "1246    0.502763\n",
      "1247    0.520844\n",
      "1248    0.516862\n",
      "1249    0.510751\n",
      "Length: 252, dtype: float64\n",
      "===========================================================================\n",
      "Truth      Down   Up\n",
      "Predicted           \n",
      "Down         35   35\n",
      "Up           76  106\n",
      "===========================================================================\n",
      "0.5595238095238095 0.44047619047619047\n"
     ]
    }
   ],
   "source": [
    "model = MS(['Lag1', 'Lag2']).fit(Smarket)\n",
    "print(Smarket)\n",
    "X = model.transform(Smarket)\n",
    "X_train, X_test = X.loc[train], X.loc[~train]\n",
    "glm_train = sm.GLM(y_train,\n",
    "                   X_train,\n",
    "                   family=sm.families.Binomial())\n",
    "results = glm_train.fit()\n",
    "probs = results.predict(exog=X_test)\n",
    "print(probs)\n",
    "labels = np.array(['Down']*Smarket_test.shape[0])\n",
    "labels[probs>0.5] = \"Up\"\n",
    "print('===========================================================================')\n",
    "print(confusion_table(labels, Smarket.Direction[~train]))\n",
    "# extracting the true labels from the data\n",
    "L_test = Smarket.Direction.loc[~train]\n",
    "print('===========================================================================')\n",
    "print(np.mean(labels == L_test), np.mean(labels != L_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a1e3f",
   "metadata": {},
   "source": [
    "# How good is this result?\n",
    "Now the results appear to be a little better: 56% of the daily movements have been correctly predicted. It is worth noting that in this case, a much simpler strategy of predicting that the market will increase every day will also be correct 56% of the time! Hence, in terms of overall error rate, the logistic regression method is no better than the naive approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38189b9c",
   "metadata": {},
   "source": [
    "# ========================================================\n",
    "# Running LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d862a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(store_covariance=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis(store_covariance=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis(store_covariance=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "# Since the LDA estimator automatically adds an intercept, we should remove the column corresponding to \n",
    "# the intercept in both X_train and X_test. We can also directly use the labels rather than the Boolean \n",
    "# vectors y_train.\n",
    "X_train, X_test = [M.drop(columns=['intercept'])\n",
    "                   for M in [X_train, X_test]]\n",
    "L_train = Smarket.Direction.loc[train]\n",
    "lda.fit(X_train, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef09c2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth      Down   Up\n",
      "Predicted           \n",
      "Down         35   35\n",
      "Up           76  106\n",
      "0.5595238095238095 0.44047619047619047\n"
     ]
    }
   ],
   "source": [
    "lda_pred = lda.predict(X_test)\n",
    "print(confusion_table(lda_pred, L_test))\n",
    "print(np.mean(lda_pred == L_test), np.mean(lda_pred != L_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf1f93",
   "metadata": {},
   "source": [
    "We see that the results are not that different than the logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b16c52",
   "metadata": {},
   "source": [
    "# ========================================================\n",
    "# Running QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd1f6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth      Down   Up\n",
      "Predicted           \n",
      "Down         30   20\n",
      "Up           81  121\n",
      "0.5992063492063492 0.4007936507936508\n"
     ]
    }
   ],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(X_train, L_train)\n",
    "qda_pred = qda.predict(X_test)\n",
    "print(confusion_table(qda_pred, L_test))\n",
    "print(np.mean(qda_pred == L_test), np.mean(qda_pred != L_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab109f",
   "metadata": {},
   "source": [
    "# How good is this result?\n",
    "This level of accuracy is quite impressive for stock market data, which is known to be quite hard to model accurately. This suggests that the quadratic form assumed by QDA may capture the true relationship more accurately than the linear forms assumed by LDA and logistic regression. However, we recommend evaluating this method’s performance on a larger test set before betting that this approach will consistently beat the market!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
