{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2d24993-d162-4f4a-900c-eca2b649395b",
   "metadata": {},
   "source": [
    "In the previous question we observed some redundancy in the features. We would like to try some feature selection heuristic in this question. Consider the same dataset as question 2 (fat.csv), where **brozek** is the response variable and the other 17 columns are the model features. Follow this steps below.<br>\n",
    "\n",
    "– Form an extended version of the dataset, by appending two more columns. One column corresponding to $siri^2$ and one column corresponding to $\\frac{1}{density}$. Your extended dataset should now have 20 columns, where the first column is brozek and used as the response variable, 17 columns identical to the original fat.csv data set, and columns 19 and 20 with the values $siri^2$ and $\\frac{1}{density}$, respectively. density\n",
    "We will refer to this dataset as the *extended dataset*.\n",
    "\n",
    "– In a similar way as question 2, split the extended dataset into two sets. Set 1 includes the first 200 rows of the data (do not count the row associated with the feature/response names), and set 2, which includes the last 52 rows of the data. Name the first set **train** and the second set **test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6704b1a9-6278-4af2-bef5-957c371a6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25c09c65-19c6-4af6-8609-b0f53cedd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fat = pd.read_csv(\"fat.csv\")\n",
    "train,test = np.split(Fat,[int(200)])\n",
    "y = train['brozek']\n",
    "X_train_full = pd.DataFrame({'intercept': np.ones(train.shape[0]),\n",
    "                  'siri':         train['siri'],\n",
    "                  'density':      train['density'],\n",
    "                  'age':          train['age'],\n",
    "                  'weight':       train['weight'],\n",
    "                  'height':       train['height'],\n",
    "                  'adipos':       train['adipos'],\n",
    "                  'free':         train['free'],\n",
    "                  'neck':         train['neck'],\n",
    "                  'chest':        train['chest'],\n",
    "                  'abdom':        train['abdom'],\n",
    "                  'hip':          train['hip'],\n",
    "                  'thigh':        train['thigh'],\n",
    "                  'knee':         train['knee'],\n",
    "                  'ankle':        train['ankle'],\n",
    "                  'biceps':       train['biceps'],\n",
    "                  'forearm':      train['forearm'],\n",
    "                  'wrist':        train['wrist'],\n",
    "                  'siri_squared': train['siri'] ** 2,\n",
    "                  'inv_density':   1/train['density']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758939d9-86f2-4a55-a7ba-019b834be8fa",
   "metadata": {},
   "source": [
    "#### (a) Use the training data to fit a model of the following form <br>brozek = $\\beta_0$ + $\\beta_1$ siri + ... + $\\beta_{17}$ wrist + $\\beta_{18}$ $siri^2$ + $\\beta_{19}$ $\\frac{1}{density}$ <br>report the fitted parameters, the 95% confidence interval for each estimated parameter and the p-values. What is the R2 value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e84177a-2fee-4ed5-8cec-d3dcf78438c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>brozek</td>      <th>  R-squared:         </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.703e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 17 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>6.09e-282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:53:25</td>     <th>  Log-Likelihood:    </th> <td>  64.717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>  -89.43</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   180</td>      <th>  BIC:               </th> <td>  -23.47</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td> -950.8057</td> <td>  580.610</td> <td>   -1.638</td> <td> 0.103</td> <td>-2096.483</td> <td>  194.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>siri</th>         <td>    0.9305</td> <td>    0.029</td> <td>   32.063</td> <td> 0.000</td> <td>    0.873</td> <td>    0.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>      <td>  436.7337</td> <td>  269.081</td> <td>    1.623</td> <td> 0.106</td> <td>  -94.225</td> <td>  967.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>          <td>   -0.0007</td> <td>    0.002</td> <td>   -0.414</td> <td> 0.680</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>    0.0162</td> <td>    0.006</td> <td>    2.809</td> <td> 0.006</td> <td>    0.005</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>height</th>       <td>   -0.0005</td> <td>    0.005</td> <td>   -0.096</td> <td> 0.924</td> <td>   -0.010</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adipos</th>       <td>   -0.0235</td> <td>    0.016</td> <td>   -1.505</td> <td> 0.134</td> <td>   -0.054</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free</th>         <td>   -0.0204</td> <td>    0.007</td> <td>   -2.780</td> <td> 0.006</td> <td>   -0.035</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neck</th>         <td>   -0.0018</td> <td>    0.011</td> <td>   -0.163</td> <td> 0.870</td> <td>   -0.024</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chest</th>        <td>    0.0056</td> <td>    0.005</td> <td>    1.026</td> <td> 0.306</td> <td>   -0.005</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abdom</th>        <td>   -0.0006</td> <td>    0.005</td> <td>   -0.109</td> <td> 0.913</td> <td>   -0.011</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hip</th>          <td>    0.0008</td> <td>    0.008</td> <td>    0.106</td> <td> 0.916</td> <td>   -0.014</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thigh</th>        <td>    0.0174</td> <td>    0.008</td> <td>    2.264</td> <td> 0.025</td> <td>    0.002</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>knee</th>         <td>   -0.0290</td> <td>    0.013</td> <td>   -2.296</td> <td> 0.023</td> <td>   -0.054</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ankle</th>        <td>    0.0061</td> <td>    0.010</td> <td>    0.591</td> <td> 0.555</td> <td>   -0.014</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>biceps</th>       <td>   -0.0169</td> <td>    0.008</td> <td>   -2.011</td> <td> 0.046</td> <td>   -0.034</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>forearm</th>      <td>    0.0219</td> <td>    0.010</td> <td>    2.110</td> <td> 0.036</td> <td>    0.001</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wrist</th>        <td>    0.0343</td> <td>    0.027</td> <td>    1.270</td> <td> 0.206</td> <td>   -0.019</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>siri_squared</th> <td>   -0.0026</td> <td>    0.001</td> <td>   -1.956</td> <td> 0.052</td> <td>   -0.005</td> <td> 2.26e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inv_density</th>  <td>  518.6225</td> <td>  312.993</td> <td>    1.657</td> <td> 0.099</td> <td>  -98.985</td> <td> 1136.230</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>98.592</td> <th>  Durbin-Watson:     </th> <td>   1.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>6766.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.902</td> <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>31.437</td> <th>  Cond. No.          </th> <td>3.19e+07</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.19e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      brozek      & \\textbf{  R-squared:         } &     0.999   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.999   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 1.703e+04   \\\\\n",
       "\\textbf{Date:}             & Wed, 17 Apr 2024 & \\textbf{  Prob (F-statistic):} & 6.09e-282   \\\\\n",
       "\\textbf{Time:}             &     20:53:25     & \\textbf{  Log-Likelihood:    } &    64.717   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &    -89.43   \\\\\n",
       "\\textbf{Df Residuals:}     &         180      & \\textbf{  BIC:               } &    -23.47   \\\\\n",
       "\\textbf{Df Model:}         &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{intercept}     &    -950.8057  &      580.610     &    -1.638  &         0.103        &    -2096.483    &      194.871     \\\\\n",
       "\\textbf{siri}          &       0.9305  &        0.029     &    32.063  &         0.000        &        0.873    &        0.988     \\\\\n",
       "\\textbf{density}       &     436.7337  &      269.081     &     1.623  &         0.106        &      -94.225    &      967.693     \\\\\n",
       "\\textbf{age}           &      -0.0007  &        0.002     &    -0.414  &         0.680        &       -0.004    &        0.003     \\\\\n",
       "\\textbf{weight}        &       0.0162  &        0.006     &     2.809  &         0.006        &        0.005    &        0.028     \\\\\n",
       "\\textbf{height}        &      -0.0005  &        0.005     &    -0.096  &         0.924        &       -0.010    &        0.009     \\\\\n",
       "\\textbf{adipos}        &      -0.0235  &        0.016     &    -1.505  &         0.134        &       -0.054    &        0.007     \\\\\n",
       "\\textbf{free}          &      -0.0204  &        0.007     &    -2.780  &         0.006        &       -0.035    &       -0.006     \\\\\n",
       "\\textbf{neck}          &      -0.0018  &        0.011     &    -0.163  &         0.870        &       -0.024    &        0.020     \\\\\n",
       "\\textbf{chest}         &       0.0056  &        0.005     &     1.026  &         0.306        &       -0.005    &        0.016     \\\\\n",
       "\\textbf{abdom}         &      -0.0006  &        0.005     &    -0.109  &         0.913        &       -0.011    &        0.010     \\\\\n",
       "\\textbf{hip}           &       0.0008  &        0.008     &     0.106  &         0.916        &       -0.014    &        0.016     \\\\\n",
       "\\textbf{thigh}         &       0.0174  &        0.008     &     2.264  &         0.025        &        0.002    &        0.033     \\\\\n",
       "\\textbf{knee}          &      -0.0290  &        0.013     &    -2.296  &         0.023        &       -0.054    &       -0.004     \\\\\n",
       "\\textbf{ankle}         &       0.0061  &        0.010     &     0.591  &         0.555        &       -0.014    &        0.026     \\\\\n",
       "\\textbf{biceps}        &      -0.0169  &        0.008     &    -2.011  &         0.046        &       -0.034    &       -0.000     \\\\\n",
       "\\textbf{forearm}       &       0.0219  &        0.010     &     2.110  &         0.036        &        0.001    &        0.042     \\\\\n",
       "\\textbf{wrist}         &       0.0343  &        0.027     &     1.270  &         0.206        &       -0.019    &        0.088     \\\\\n",
       "\\textbf{siri\\_squared} &      -0.0026  &        0.001     &    -1.956  &         0.052        &       -0.005    &     2.26e-05     \\\\\n",
       "\\textbf{inv\\_density}  &     518.6225  &      312.993     &     1.657  &         0.099        &      -98.985    &     1136.230     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 98.592 & \\textbf{  Durbin-Watson:     } &    1.907  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } & 6766.061  \\\\\n",
       "\\textbf{Skew:}          &  0.902 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      & 31.437 & \\textbf{  Cond. No.          } & 3.19e+07  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 3.19e+07. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 brozek   R-squared:                       0.999\n",
       "Model:                            OLS   Adj. R-squared:                  0.999\n",
       "Method:                 Least Squares   F-statistic:                 1.703e+04\n",
       "Date:                Wed, 17 Apr 2024   Prob (F-statistic):          6.09e-282\n",
       "Time:                        20:53:25   Log-Likelihood:                 64.717\n",
       "No. Observations:                 200   AIC:                            -89.43\n",
       "Df Residuals:                     180   BIC:                            -23.47\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "intercept     -950.8057    580.610     -1.638      0.103   -2096.483     194.871\n",
       "siri             0.9305      0.029     32.063      0.000       0.873       0.988\n",
       "density        436.7337    269.081      1.623      0.106     -94.225     967.693\n",
       "age             -0.0007      0.002     -0.414      0.680      -0.004       0.003\n",
       "weight           0.0162      0.006      2.809      0.006       0.005       0.028\n",
       "height          -0.0005      0.005     -0.096      0.924      -0.010       0.009\n",
       "adipos          -0.0235      0.016     -1.505      0.134      -0.054       0.007\n",
       "free            -0.0204      0.007     -2.780      0.006      -0.035      -0.006\n",
       "neck            -0.0018      0.011     -0.163      0.870      -0.024       0.020\n",
       "chest            0.0056      0.005      1.026      0.306      -0.005       0.016\n",
       "abdom           -0.0006      0.005     -0.109      0.913      -0.011       0.010\n",
       "hip              0.0008      0.008      0.106      0.916      -0.014       0.016\n",
       "thigh            0.0174      0.008      2.264      0.025       0.002       0.033\n",
       "knee            -0.0290      0.013     -2.296      0.023      -0.054      -0.004\n",
       "ankle            0.0061      0.010      0.591      0.555      -0.014       0.026\n",
       "biceps          -0.0169      0.008     -2.011      0.046      -0.034      -0.000\n",
       "forearm          0.0219      0.010      2.110      0.036       0.001       0.042\n",
       "wrist            0.0343      0.027      1.270      0.206      -0.019       0.088\n",
       "siri_squared    -0.0026      0.001     -1.956      0.052      -0.005    2.26e-05\n",
       "inv_density    518.6225    312.993      1.657      0.099     -98.985    1136.230\n",
       "==============================================================================\n",
       "Omnibus:                       98.592   Durbin-Watson:                   1.907\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6766.061\n",
       "Skew:                           0.902   Prob(JB):                         0.00\n",
       "Kurtosis:                      31.437   Cond. No.                     3.19e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.19e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullFittedModel = sm.OLS(y, X_train_full).fit()\n",
    "fullFittedModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22b57a2d-3038-4b03-8d45-7484053c8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_full = pd.DataFrame({'intercept': np.ones(test.shape[0]),\n",
    "                  'siri':    test['siri'],\n",
    "                  'density': test['density'],\n",
    "                  'age':     test['age'],\n",
    "                  'weight':  test['weight'],\n",
    "                  'height':  test['height'],\n",
    "                  'adipos':  test['adipos'],\n",
    "                  'free':    test['free'],\n",
    "                  'neck':    test['neck'],\n",
    "                  'chest':   test['chest'],\n",
    "                  'abdom':   test['abdom'],\n",
    "                  'hip':     test['hip'],\n",
    "                  'thigh':   test['thigh'],\n",
    "                  'knee':    test['knee'],\n",
    "                  'ankle':   test['ankle'],\n",
    "                  'biceps':  test['biceps'],\n",
    "                  'forearm': test['forearm'],\n",
    "                  'wrist':   test['wrist'],\n",
    "                  'siri_squared': test['siri'] ** 2,\n",
    "                  'inv_density':   1/test['density']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4209d36-a91f-4f0d-93a7-910b2e8b82a3",
   "metadata": {},
   "source": [
    "#### (b) Use the test data to calculate the test error (similar to the formulation in part (c) of the previous question), and call it $e_{full}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84936a77-a2c4-4e52-ae13-2c4e1a18c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the problematic features that has p-value over 0.03\n",
    "def get_prediction_error(model, X_pred):\n",
    "    # the actual value from test dataset\n",
    "    y_actual = np.array(test['brozek'].values)\n",
    "    # the value predicted by the full-features model\n",
    "    y_prediction = np.array(model.predict(X_pred))\n",
    "    return np.sqrt(sum(np.square(y_actual - y_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b57bd656-2df4-43c0-a7b7-e7706014f17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Error e_full = 0.8565466791992765\n"
     ]
    }
   ],
   "source": [
    "# Calculate the prediction error of full-featured model\n",
    "print('Prediction Error e_full =', get_prediction_error(fullFittedModel, X_test_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d730c28-b593-4a01-9b71-633a8d397c9b",
   "metadata": {},
   "source": [
    "#### (c) Let’s run a heuristic scheme to perform feature selection (the method is called backward selection and described on page 79 of your textbook, also on the slides). Start with the full model (the model containing all 19 features of the extended dataset) and drop the feature with the highest p-value (or the second largest if the largest p-value is for the intercept), then redo the modeling and drop the next feature with the highest p-value, and continue dropping until all p-values are small and you are left with a set of important features. Implement this approach and stop when all p-values are below 0.03. Which features are selected as the most important ones when your code stops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fb46082-fa1a-4948-8fa0-a8e1ff9995ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the problematic features that has p-value greater than 0.03, among all the p-values.\n",
    "def get_problematic_pValues(model):\n",
    "    pv = model.pvalues\n",
    "    return pv[pv > 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71bb1023-e9f6-417a-89bd-034b96b0af4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>brozek</td>      <th>  R-squared (uncentered):</th>      <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>5.569e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 17 Apr 2024</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:53:25</td>     <th>  Log-Likelihood:    </th>          <td>  51.369</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th>          <td>  -94.74</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th>          <td>  -81.55</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>siri</th>        <td>    0.9222</td> <td>    0.002</td> <td>  474.600</td> <td> 0.000</td> <td>    0.918</td> <td>    0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thigh</th>       <td>    0.0142</td> <td>    0.005</td> <td>    3.101</td> <td> 0.002</td> <td>    0.005</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>knee</th>        <td>   -0.0262</td> <td>    0.010</td> <td>   -2.596</td> <td> 0.010</td> <td>   -0.046</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inv_density</th> <td>    1.5192</td> <td>    0.267</td> <td>    5.698</td> <td> 0.000</td> <td>    0.993</td> <td>    2.045</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>187.007</td> <th>  Durbin-Watson:     </th> <td>   1.919</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>13874.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.978</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>43.367</td>  <th>  Cond. No.          </th> <td>1.47e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 1.47e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      brozek      & \\textbf{  R-squared (uncentered):}      &     1.000   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     1.000   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          & 5.569e+05   \\\\\n",
       "\\textbf{Date:}             & Wed, 17 Apr 2024 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}             &     20:53:25     & \\textbf{  Log-Likelihood:    }          &    51.369   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               }          &    -94.74   \\\\\n",
       "\\textbf{Df Residuals:}     &         196      & \\textbf{  BIC:               }          &    -81.55   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{siri}         &       0.9222  &        0.002     &   474.600  &         0.000        &        0.918    &        0.926     \\\\\n",
       "\\textbf{thigh}        &       0.0142  &        0.005     &     3.101  &         0.002        &        0.005    &        0.023     \\\\\n",
       "\\textbf{knee}         &      -0.0262  &        0.010     &    -2.596  &         0.010        &       -0.046    &       -0.006     \\\\\n",
       "\\textbf{inv\\_density} &       1.5192  &        0.267     &     5.698  &         0.000        &        0.993    &        2.045     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 187.007 & \\textbf{  Durbin-Watson:     } &     1.919  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 13874.811  \\\\\n",
       "\\textbf{Skew:}          &   2.978 & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  43.367 & \\textbf{  Cond. No.          } &  1.47e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [3] The condition number is large, 1.47e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                 brozek   R-squared (uncentered):                   1.000\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
       "Method:                 Least Squares   F-statistic:                          5.569e+05\n",
       "Date:                Wed, 17 Apr 2024   Prob (F-statistic):                        0.00\n",
       "Time:                        20:53:25   Log-Likelihood:                          51.369\n",
       "No. Observations:                 200   AIC:                                     -94.74\n",
       "Df Residuals:                     196   BIC:                                     -81.55\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "siri            0.9222      0.002    474.600      0.000       0.918       0.926\n",
       "thigh           0.0142      0.005      3.101      0.002       0.005       0.023\n",
       "knee           -0.0262      0.010     -2.596      0.010      -0.046      -0.006\n",
       "inv_density     1.5192      0.267      5.698      0.000       0.993       2.045\n",
       "==============================================================================\n",
       "Omnibus:                      187.007   Durbin-Watson:                   1.919\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13874.811\n",
       "Skew:                           2.978   Prob(JB):                         0.00\n",
       "Kurtosis:                      43.367   Cond. No.                     1.47e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 1.47e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the problematic features\n",
    "pv_problematic = get_problematic_pValues(fullFittedModel)\n",
    "# print(pv_problematic,\"\\n\")\n",
    "\n",
    "# Training set for iteration\n",
    "X_train_new = X_train_full\n",
    "\n",
    "# Run the loop if there is any p-value greater than 0.03\n",
    "while (pv_problematic > 0.03).any():\n",
    "\n",
    "    # Find the most problematic feature\n",
    "    fea_maxP = pv_problematic.idxmax()\n",
    "    # print(fea_maxP,\": \", pv_problematic[fea_maxP])\n",
    "\n",
    "    # Drop that feature and get new training data\n",
    "    X_train_new = X_train_new.drop(fea_maxP, axis = 1)\n",
    "\n",
    "    # Retrain the model with new data\n",
    "    newFittedModel = sm.OLS(y, X_train_new).fit()\n",
    "\n",
    "    # Get new p-valuses from new model\n",
    "    pv_problematic = get_problematic_pValues(newFittedModel)\n",
    "\n",
    "newFittedModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb85d0-2a85-4b01-84d8-89f8d69b7750",
   "metadata": {},
   "source": [
    "#### *siri*, *thigh*, *knee*, *$\\frac{1}{density}$* are the most important features after backward selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972bc381-546b-4104-8eab-44f9d7193b2f",
   "metadata": {},
   "source": [
    "#### (d) Apply the model developed in part (c) to the test data and call the error $e_{sel}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46f23c5e-ef67-4332-a347-59a757b2abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Error e_sel = 0.6670935385386173\n"
     ]
    }
   ],
   "source": [
    "# Feature variables from test set\n",
    "X_test_sel = pd.DataFrame({'siri': test['siri'], 'thigh': test['thigh'], 'knee': test['knee'], 'inv_density': 1/test['density']})\n",
    "\n",
    "# Calculate\n",
    "print('Prediction Error e_sel =', get_prediction_error(newFittedModel, X_test_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2124e7b-f6e5-4714-a578-73b6297014f8",
   "metadata": {},
   "source": [
    "#### (e) Compare $e_{full}$ and $e_{sel}$. Does the feature selection scheme seem to reduce overfitting?\n",
    "\n",
    "#### Yes, it does reduce overfitting. By removing less important features, backward selection helps focus the model on the most relevant predictors. This reduces the complexity of the model and decrease the chance of fitting too close to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad15f0c-99b5-4cef-9f44-4e601ffc3e28",
   "metadata": {},
   "source": [
    "#### (f) Compare $e_{sel}$ with $e_3$ from part (h) of question 2. In terms of the test accuracy does your feature selection scheme seem to find the best model?\n",
    "\n",
    "#### $e_{sel}$ (*0.6670935385386173*) is greater than $e_3$ (*0.563361670359713*), therefore, the feature selection scheme seems not to get the best model in this case. The reason might be some useful features that seemed not important were removed too early. This can lead to a loss of valuable information that could be useful in conjunction with other features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
