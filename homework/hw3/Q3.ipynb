{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25618b64-9024-49e8-8a18-4f32399e9ca7",
   "metadata": {},
   "source": [
    "#### The goal of this question is predicting the heart health of patients in a hospital. In the homework package, you can access the data file **“HeartData.csv”**, which consists of 13 features and one response variable (num). The features represent some measurements of the patients’ health atributes and num is an indication of the heart health. If num = 0, the heart is healthy, and if num = 1, it reports an issue.\n",
    "\n",
    "#### Consider splitting the data into a a training and test set. Samples 1 to 200 form the training set and samples 201 to 297 form the test set. Try the following classification models to predict “num” in terms of the other features in the dataset:\n",
    "    – Use logistic regression for your classification. Report the p-values associated with the intercept and all the features. Which features have large p-values? Use the test data to estimate the accuracy of your model.\n",
    "    – Apply LDA and QDA, and again report your model accuracies using the test data.\n",
    "    – Among logistic regression, LDA, and QDA which model(s) seems the most accurate one(s)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3447c327-9d47-4511-90f0-f9dbf3dfdc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3029711a-63ef-4d9d-aef8-cb62e6a3935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= = = = = = = = = = = Coefficient = = = = = = = = = = =\n",
      "β0: -0.7775994625128763 , β1: 1.2088079596901309\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('BinaryData.csv')\n",
    "# print(data)\n",
    "X_train = pd.DataFrame({'intercept': np.ones(train.shape[0]), 'x': data['x']})\n",
    "# print(X_train)\n",
    "y_train = (data.y == 1)\n",
    "glm_train = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "results = glm_train.fit()\n",
    "print(\"= = = = = = = = = = = Coefficient = = = = = = = = = = =\")\n",
    "beta_0, beta_1 = results.params.intercept, results.params.x\n",
    "print(\"β0:\", beta_0, \", β1:\", beta_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
