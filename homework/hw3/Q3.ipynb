{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25618b64-9024-49e8-8a18-4f32399e9ca7",
   "metadata": {},
   "source": [
    "#### The goal of this question is predicting the heart health of patients in a hospital. In the homework package, you can access the data file **“HeartData.csv”**, which consists of 13 features and one response variable (num). The features represent some measurements of the patients’ health atributes and num is an indication of the heart health. If num = 0, the heart is healthy, and if num = 1, it reports an issue.\n",
    "\n",
    "#### Consider splitting the data into a a training and test set. Samples 1 to 200 form the training set and samples 201 to 297 form the test set. Try the following classification models to predict “num” in terms of the other features in the dataset:\n",
    "    – Use logistic regression for your classification. Report the p-values associated with the intercept and all the features. Which features have large p-values? Use the test data to estimate the accuracy of your model.\n",
    "    – Apply LDA and QDA, and again report your model accuracies using the test data.\n",
    "    – Among logistic regression, LDA, and QDA which model(s) seems the most accurate one(s)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3447c327-9d47-4511-90f0-f9dbf3dfdc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize)\n",
    "from ISLP import confusion_table\n",
    "from sklearn.discriminant_analysis import \\\n",
    "     (LinearDiscriminantAnalysis as LDA,\n",
    "      QuadraticDiscriminantAnalysis as QDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94d45e-6d44-42ba-9d93-0b6807d845a2",
   "metadata": {},
   "source": [
    "# = = = = = Logistic Regression = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ea34c10-a2e9-4328-b16f-369e5fe4350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0     63    1   1       145   233    1        2      150      0      2.3   \n",
      "1     67    1   4       160   286    0        2      108      1      1.5   \n",
      "2     67    1   4       120   229    0        2      129      1      2.6   \n",
      "3     37    1   3       130   250    0        0      187      0      3.5   \n",
      "4     41    0   2       130   204    0        2      172      0      1.4   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "292   57    0   4       140   241    0        0      123      1      0.2   \n",
      "293   45    1   1       110   264    0        0      132      0      1.2   \n",
      "294   68    1   4       144   193    1        0      141      0      3.4   \n",
      "295   57    1   4       130   131    0        0      115      1      1.2   \n",
      "296   57    0   2       130   236    0        2      174      0      0.0   \n",
      "\n",
      "     slope  ca  thal  num  \n",
      "0        3   0     6    0  \n",
      "1        2   3     3    1  \n",
      "2        2   2     7    1  \n",
      "3        3   0     3    0  \n",
      "4        1   0     3    0  \n",
      "..     ...  ..   ...  ...  \n",
      "292      2   0     7    1  \n",
      "293      2   0     7    1  \n",
      "294      2   2     7    1  \n",
      "295      2   1     7    1  \n",
      "296      2   1     3    1  \n",
      "\n",
      "[297 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "Data = pd.read_csv('HeartData.csv')\n",
    "train = (Data.index < 200)\n",
    "X = MS(Data.columns.drop(['num'])).fit_transform(Data)\n",
    "Y = Data['num']\n",
    "print(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3029711a-63ef-4d9d-aef8-cb62e6a3935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "195    0\n",
      "196    1\n",
      "197    0\n",
      "198    0\n",
      "199    0\n",
      "Name: num, Length: 200, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>num</td>       <th>  No. Observations:  </th>  <td>   200</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   186</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -63.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 15 May 2024</td> <th>  Deviance:          </th> <td>  126.96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:42:11</td>     <th>  Pearson chi2:      </th>  <td>  174.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.5236</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>  -10.3711</td> <td>    3.716</td> <td>   -2.791</td> <td> 0.005</td> <td>  -17.655</td> <td>   -3.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>   -0.0073</td> <td>    0.031</td> <td>   -0.236</td> <td> 0.813</td> <td>   -0.068</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>       <td>    1.8161</td> <td>    0.703</td> <td>    2.582</td> <td> 0.010</td> <td>    0.438</td> <td>    3.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp</th>        <td>    0.9642</td> <td>    0.290</td> <td>    3.324</td> <td> 0.001</td> <td>    0.396</td> <td>    1.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trestbps</th>  <td>    0.0341</td> <td>    0.014</td> <td>    2.432</td> <td> 0.015</td> <td>    0.007</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>      <td>    0.0075</td> <td>    0.005</td> <td>    1.583</td> <td> 0.113</td> <td>   -0.002</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs</th>       <td>   -1.0563</td> <td>    0.654</td> <td>   -1.616</td> <td> 0.106</td> <td>   -2.337</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restecg</th>   <td>    0.4627</td> <td>    0.244</td> <td>    1.894</td> <td> 0.058</td> <td>   -0.016</td> <td>    0.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalach</th>   <td>   -0.0285</td> <td>    0.014</td> <td>   -1.967</td> <td> 0.049</td> <td>   -0.057</td> <td>-9.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exang</th>     <td>    0.6358</td> <td>    0.524</td> <td>    1.214</td> <td> 0.225</td> <td>   -0.390</td> <td>    1.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oldpeak</th>   <td>    0.2416</td> <td>    0.260</td> <td>    0.928</td> <td> 0.353</td> <td>   -0.268</td> <td>    0.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>     <td>    0.5692</td> <td>    0.454</td> <td>    1.252</td> <td> 0.210</td> <td>   -0.322</td> <td>    1.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>        <td>    0.9591</td> <td>    0.316</td> <td>    3.031</td> <td> 0.002</td> <td>    0.339</td> <td>    1.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thal</th>      <td>    0.3448</td> <td>    0.128</td> <td>    2.689</td> <td> 0.007</td> <td>    0.093</td> <td>    0.596</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &       num        & \\textbf{  No. Observations:  } &      200    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &      186    \\\\\n",
       "\\textbf{Model Family:}    &     Binomial     & \\textbf{  Df Model:          } &       13    \\\\\n",
       "\\textbf{Link Function:}   &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -63.478   \\\\\n",
       "\\textbf{Date:}            & Wed, 15 May 2024 & \\textbf{  Deviance:          } &    126.96   \\\\\n",
       "\\textbf{Time:}            &     13:42:11     & \\textbf{  Pearson chi2:      } &     174.    \\\\\n",
       "\\textbf{No. Iterations:}  &        6         & \\textbf{  Pseudo R-squ. (CS):} &   0.5236    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{intercept} &     -10.3711  &        3.716     &    -2.791  &         0.005        &      -17.655    &       -3.087     \\\\\n",
       "\\textbf{age}       &      -0.0073  &        0.031     &    -0.236  &         0.813        &       -0.068    &        0.054     \\\\\n",
       "\\textbf{sex}       &       1.8161  &        0.703     &     2.582  &         0.010        &        0.438    &        3.195     \\\\\n",
       "\\textbf{cp}        &       0.9642  &        0.290     &     3.324  &         0.001        &        0.396    &        1.533     \\\\\n",
       "\\textbf{trestbps}  &       0.0341  &        0.014     &     2.432  &         0.015        &        0.007    &        0.062     \\\\\n",
       "\\textbf{chol}      &       0.0075  &        0.005     &     1.583  &         0.113        &       -0.002    &        0.017     \\\\\n",
       "\\textbf{fbs}       &      -1.0563  &        0.654     &    -1.616  &         0.106        &       -2.337    &        0.225     \\\\\n",
       "\\textbf{restecg}   &       0.4627  &        0.244     &     1.894  &         0.058        &       -0.016    &        0.942     \\\\\n",
       "\\textbf{thalach}   &      -0.0285  &        0.014     &    -1.967  &         0.049        &       -0.057    &    -9.99e-05     \\\\\n",
       "\\textbf{exang}     &       0.6358  &        0.524     &     1.214  &         0.225        &       -0.390    &        1.662     \\\\\n",
       "\\textbf{oldpeak}   &       0.2416  &        0.260     &     0.928  &         0.353        &       -0.268    &        0.752     \\\\\n",
       "\\textbf{slope}     &       0.5692  &        0.454     &     1.252  &         0.210        &       -0.322    &        1.460     \\\\\n",
       "\\textbf{ca}        &       0.9591  &        0.316     &     3.031  &         0.002        &        0.339    &        1.579     \\\\\n",
       "\\textbf{thal}      &       0.3448  &        0.128     &     2.689  &         0.007        &        0.093    &        0.596     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                    num   No. Observations:                  200\n",
       "Model:                            GLM   Df Residuals:                      186\n",
       "Model Family:                Binomial   Df Model:                           13\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -63.478\n",
       "Date:                Wed, 15 May 2024   Deviance:                       126.96\n",
       "Time:                        13:42:11   Pearson chi2:                     174.\n",
       "No. Iterations:                     6   Pseudo R-squ. (CS):             0.5236\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept    -10.3711      3.716     -2.791      0.005     -17.655      -3.087\n",
       "age           -0.0073      0.031     -0.236      0.813      -0.068       0.054\n",
       "sex            1.8161      0.703      2.582      0.010       0.438       3.195\n",
       "cp             0.9642      0.290      3.324      0.001       0.396       1.533\n",
       "trestbps       0.0341      0.014      2.432      0.015       0.007       0.062\n",
       "chol           0.0075      0.005      1.583      0.113      -0.002       0.017\n",
       "fbs           -1.0563      0.654     -1.616      0.106      -2.337       0.225\n",
       "restecg        0.4627      0.244      1.894      0.058      -0.016       0.942\n",
       "thalach       -0.0285      0.014     -1.967      0.049      -0.057   -9.99e-05\n",
       "exang          0.6358      0.524      1.214      0.225      -0.390       1.662\n",
       "oldpeak        0.2416      0.260      0.928      0.353      -0.268       0.752\n",
       "slope          0.5692      0.454      1.252      0.210      -0.322       1.460\n",
       "ca             0.9591      0.316      3.031      0.002       0.339       1.579\n",
       "thal           0.3448      0.128      2.689      0.007       0.093       0.596\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, X_train = Y.loc[train] , X.loc[train]\n",
    "y_test, X_test = Y.loc[~train] , X.loc[~train]\n",
    "print(y_train)\n",
    "LogisticRegressionModel = sm.GLM(y_train, X_train, family=sm.families.Binomial()).fit()\n",
    "LogisticRegressionModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37e3c350-0ba3-4aab-8cfd-f72494eeafbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "200    False\n",
      "201    False\n",
      "202     True\n",
      "203     True\n",
      "204     True\n",
      "       ...  \n",
      "292     True\n",
      "293    False\n",
      "294     True\n",
      "295     True\n",
      "296    False\n",
      "Length: 97, dtype: bool\n",
      "(97,)\n",
      "Truth       0   1\n",
      "Predicted        \n",
      "0          46  15\n",
      "1           4  32\n",
      "===========================================================================\n",
      "True rate: 0.8041237113402062 , False rate: 0.1958762886597938\n"
     ]
    }
   ],
   "source": [
    "probs = LogisticRegressionModel.predict(exog=X_test)\n",
    "print('===========================================================================')\n",
    "labels = np.array([0]*y_test.shape[0])\n",
    "print(probs>0.5)\n",
    "labels[probs>0.5] = 1\n",
    "print(probs.shape)\n",
    "print(confusion_table(labels, y_test))\n",
    "print('===========================================================================')\n",
    "print('True rate:', np.mean(labels == y_test), ', False rate:', np.mean(labels != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb067b58-b791-4a1e-a44f-ca45feaa8f42",
   "metadata": {},
   "source": [
    "# = = = = = Running LDA = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02b12734-463a-4e9e-ad0d-1094317cb213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "[0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0]\n",
      "[0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0]\n",
      "Truth       0   1\n",
      "Predicted        \n",
      "0          46  14\n",
      "1           4  33\n",
      "True rate: 0.8144329896907216 , False rate: 0.18556701030927836\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "# Since the LDA estimator automatically adds an intercept, we should remove the column corresponding to \n",
    "# the intercept in both X_train and X_test. We can also directly use the labels rather than the Boolean \n",
    "# vectors y_train.\n",
    "\n",
    "if 'intercept' in X_train:\n",
    "    X_train, X_test = [M.drop(columns=['intercept'], axis = 1) for M in [X_train, X_test]]\n",
    "    # print(X_test)\n",
    "print('===========================================================================')\n",
    "# print(y_train)\n",
    "lda.fit(X_train, y_train)\n",
    "lda_pred = lda.predict(X_test)\n",
    "print(labels)\n",
    "print(lda_pred)\n",
    "print(confusion_table(lda_pred, y_test))\n",
    "print('True rate:', np.mean(lda_pred == y_test), ', False rate:', np.mean(lda_pred != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a0628-d76c-4ee6-a82a-72927f2330bb",
   "metadata": {},
   "source": [
    "# = = = = = Running QDA = = = = ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a28dbf44-1daa-4a23-84f9-5f819cd9e796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth       0   1\n",
      "Predicted        \n",
      "0          46  15\n",
      "1           4  32\n",
      "0.8041237113402062 0.1958762886597938\n"
     ]
    }
   ],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(X_train, y_train)\n",
    "qda_pred = qda.predict(X_test)\n",
    "print(confusion_table(qda_pred, y_test))\n",
    "print(np.mean(qda_pred == y_test), np.mean(qda_pred != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aff601-9921-4caf-954d-c9d54c85b760",
   "metadata": {},
   "source": [
    "#### Among these models, ***LDA*** seems to be the most accurate model.\n",
    "#### ***QDA*** is less accurate since it might be overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
