# AI 539: Machine Learning for Non-Majors (Spring 2024)

### Course Summary
This course covers a set of topics in machine learning and artificial intelligence, suitable for master of science students, mainly non-CS majors. Topics include supervised and unsupervised learning, linear and nonlinear regression/classification, and boosting techniques. Students will gain a solid understanding of machine learning fundamentals and will be equipped to apply these concepts to real-world and research problems.

### Instructor Information
- **Instructor:** Alireza (Ali) Aghasi
- **Office:** Room 3121, Kelley Engineering Building
- **Email:** [alireza.aghasi@oregonstate.edu](mailto:alireza.aghasi@oregonstate.edu)
- **Office Hours:**
  - Wednesdays, Noon-1p (Zoom only: [Link](https://oregonstate.zoom.us/j/2272200572?pwd=c1dPRlF1akY4QzRJUS9wOFVGaGIrQT09))
  - Fridays, in person, 12:30 pm - 1:30 pm

### Course Information
- **Location:** Room 320, Bexell Hall
- **Class Days:** Mondays and Wednesdays
- **Website:** [Canvas](https://canvas.oregonstate.edu/courses/1954644)
- **Forum:** [Ed-Discussion](https://edstem.org/us/courses/57825/discussion/)
- **Teaching Assistant:** TBA
- **Prerequisites:** Previous course in probability and statistics, familiarity with computer programming, linear algebra, calculus
- **Software:** Python, MATLAB

### Lecture Notes and Texts
- Lecture slides and notes will be posted on Canvas. It is recommended that students take notes during class for additional details.
- **Main Texts:**
  - James, G., Witten, D., Hastie, T., Tibshirani, R., Taylor, J., "An **I**ntroduction to **S**tatistical **L**earning: with Applications in Python", Springer, 2023. [E-book](https://www.statlearning.com/)
  - Hastie, T., Tibshirani, R., Friedman, J., "The **E**lements of **S**tatistical **L**earning: Data Mining, Inference, and Prediction", Second Edition, Springer, 2009. [E-book](https://goo.gl/xgr63x)

### Additional (Optional) Readings
- Bishop, C., "Pattern Recognition and Machine Learning", Springer, 2006. [URL](https://goo.gl/56GFVv)
- Mitchell, T.M., "Machine Learning", McGraw-Hill, 1997. [URL](https://goo.gl/HrBDtK)

### Grading
- **Homework:** 25%
- **Midterm:** 35%
- **Final Project:** 35%
- **Attendance:** 5%
- **Final Grade Conversion:**

  | A | A- | B+ | B | B- | C+ | C | C- |
  | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
  | ≥ 93 | ≥ 90 | ≥ 87 | ≥ 84 | ≥ 80 | ≥ 77 | ≥ 74 | ≥ 70 |

### Homework
Homework will be assigned on a weekly or biweekly basis (more assignments at the beginning of the term). Homework will be turned in on the date/time specified on Canvas. **All HWs are submitted online.** <br>
**Late homework is not accepted** and will receive zero credit. You should start working on each homework early, that way you will have enough time to ask questions in the class before the due date.<br>
Each student must write up and turn in their own solutions. While discussing the home- work problems among the students is encouraged, students copying from their classmates or from any other resources will receive a zero score.
Effectively, homework is worth much more than 25% of your grade. It is extremely unlikely that ones does well on the exam without putting enough effort into the homework.

### Lecture Outline
| Topic | Reading |
| - | - |
| Introduction to learning theory and fundamental notions | ISL.1-2 |
| Linear regression and extensions | ISL.3, ESL.3 |
| Theory Session 1: Maximum Likelihood, Optimization, Gradient Descent, Convexity | - |
| Classification methods like logistic regression, LDA, QDA | ISL.4, ESL.4 |
| Theory Session 2: Bootstrapping, Complexity (VC dimension), ... | ISL.5, ESL.7 |
| Model validation and selection techniques | ISL.5, ESL.7, 8, 10 |
| Model Selection: Greedy Approaches, Regularization, Ridge, Lasso  | ISL.6, ESL.7, 10 |
| Singular Value Decomposition, PCA, PCR | ISL6, 10 |
| Nonlinear learning modules, neural networks, deep learning | ESL.11 |
| Tree-based methods (random forests, decision trees, ...) | ISL.8, ESL.9 |
| Intro to Deep GANs & Unsupervised learning (PCA, K-means, ...) | ISL.10 |
| Final presentations (all groups) | - |

### Lecture Video
| Date | Passcode | Topic |
| - | - | - |
| [Apr.3 2024](https://oregonstate.zoom.us/rec/share/6yNGpLQ2sflQ9bi4wefIHLyox2mnlmrLl2DbIqsVscmWjt22J2AkDAXKOezqOnB5.sRqjfqwghzisVI9R) | .d@ky2@U | Introduction of Machine Learning |
| [Apr.8 2024](https://oregonstate.zoom.us/rec/share/AfEQGDEQ1VdbLPGeFNwOSm8Pp9U4qJEwdEkf6QcCoASltZ--sH8GLzhxBGxbvEzK.OZ0EYsLfR9vdkN_8) | @6J94s?P | Hypothesis Testing and Linear Regression |
| [Apr.10 2024](https://oregonstate.zoom.us/rec/share/9djbE-uw6itqXm3dG_1fWHKQ5L4N7j2TScwEKwmkBgmMuNcaQNyPC442BMLgzAFy.i5H1yCVlzZJCN2TL) | GfPE=7B9 | Multiple Linear Regression |
| [Apr.15 2024](https://oregonstate.zoom.us/rec/share/6hQH-GHtnyBjL-kcRIhJagUqaxkk6JYwiVWu0G5yOJP7Buls0CCTg4RBE0_No5y6.r7T5ESnhpnQsagJm) | 6$K6SyK7 | Sampling Distribution & Gradient Descent |
| [Apr.17 2024](https://oregonstate.zoom.us/rec/share/fU_wGBhR6cqEqvMKuVgZ7SCu5_iIk3ciFLzmma7YGcq1tcBorwb3oaoxYZF-JnEe.d-vxj9OB0l2Me6My) | s98#r#v. | GD with Momentum and Convex Function |
| [Apr.22 2024]() |  |  |
| [Apr.24 2024]() |  |  |
| [Apr.29 2024]() |  |  |

